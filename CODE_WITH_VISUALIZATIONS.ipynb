{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"K1ig5HyVEQw-"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"K1ig5HyVEQw-"},{"cell_type":"code","execution_count":null,"metadata":{"id":"37516982"},"outputs":[],"source":["import pandas as pd\n","left = pd.read_csv('left_dataset.csv')\n","right = pd.read_csv('right_dataset.csv')\n","\n","#see number of rows in the two dataframe\n","print(\"left:\", left.shape[0], \"right:\", right.shape[0])"],"id":"37516982"},{"cell_type":"code","execution_count":null,"metadata":{"id":"928db68e"},"outputs":[],"source":["#clean left dataset\n","\n","#lower case\n","left[[\"name\", \"address\", \"city\"]] = left[[\"name\", \"address\", \"city\"]].astype(str).applymap(str.lower)\n","\n","#fill NA and change to integer in postal code\n","left[\"postal_code\"] = left[\"postal_code\"].fillna(0).astype(int)\n","\n","#drop column \"categories\"\n","left.drop(columns=[\"categories\"], inplace=True)\n","\n","#replace all non-alphanumeric and non-space characters with an empty string\n","left[\"name\"] = left[\"name\"].str.replace(r'[^\\w\\s]','', regex=True)\n","left[\"address\"] = left[\"address\"].str.replace(r'[^\\w\\s]','', regex=True)\n","\n","#strip leading spaces for name and then sort\n","left[\"name\"] = left[\"name\"].str.strip()\n","left = left.sort_values(by=\"name\", ascending=True)\n","\n","#see first few rows\n","left.head()"],"id":"928db68e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4a97e091"},"outputs":[],"source":["#check for duplicates\n","duplicate_left = left[left.duplicated(['name', 'address'])]\n","duplicate_left"],"id":"4a97e091"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2b52d6c1"},"outputs":[],"source":["#drop duplicates\n","left_no_duplicates = left.drop_duplicates(subset=['name', 'address'], keep='first')\n","print(\"left:\", left_no_duplicates.shape[0])"],"id":"2b52d6c1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3a71f3a4"},"outputs":[],"source":["#clean right dataset\n","\n","#lower case and drop trailing and leading spaces\n","right[[\"name\", \"address\", \"city\"]] = right[[\"name\", \"address\", \"city\"]].astype(str).applymap(str.lower)\n","\n","#fill NA and change to integer in zip code\n","right[\"zip_code\"] = right[\"zip_code\"].str[:5].fillna(0).astype(int)\n","\n","#drop column \"size\"\n","right.drop(columns=[\"size\"], inplace=True)\n","\n","#replace all llc and inc and non-alphanumeric and non-space characters with an empty string\n","right[\"name\"] = right[\"name\"].str.replace(\"inc\", \"\").str.replace(\"llc\", \"\").str.replace(r'[^\\w\\s]','', regex=True)\n","right[\"address\"] = right[\"address\"].str.replace(r'[^\\w\\s]','', regex=True)\n","\n","#strip leading spaces for name and then sort\n","right[\"name\"] = right[\"name\"].str.strip()\n","right = right.sort_values(by=\"name\", ascending=True)\n","\n","#see first few rows\n","right.head()"],"id":"3a71f3a4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3d2c7ab5"},"outputs":[],"source":["#check for duplicates\n","duplicate_right = right[right.duplicated(['name', 'address'])]\n","duplicate_right"],"id":"3d2c7ab5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"659441ac"},"outputs":[],"source":["#drop duplicates\n","right_no_duplicates = right.drop_duplicates(subset=['name', 'address'], keep='first')\n","print(\"right:\", right_no_duplicates.shape[0])"],"id":"659441ac"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3e8b195f"},"outputs":[],"source":["# Plot a bar chart of the state counts\n","import matplotlib.pyplot as plt\n","\n","state_counts_left = left_no_duplicates['state'].value_counts()\n","state_counts_right = right_no_duplicates['state'].value_counts()\n","\n","state_counts = pd.DataFrame({\n","    'Left': state_counts_left,\n","    'Right': state_counts_right\n","}).fillna(0)\n","\n","ax = state_counts.plot(kind='bar', figsize=(10, 5))\n","ax.set_xlabel('State')\n","ax.set_ylabel('Count')\n","\n","ax.legend()\n","plt.show()\n"],"id":"3e8b195f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"tSsjFFWVyfpK"},"outputs":[],"source":["# group the data by company name and count the number of addresses in the left dataframe\n","left_counts = left_no_duplicates.groupby('name').count()['address']\n","\n","# count the number of companies with the same number of addresses in the left dataframe, sorted by count of addresses in descending order\n","print(left_counts.value_counts().sort_index(ascending=False))\n"],"id":"tSsjFFWVyfpK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQtdWDXPymA1"},"outputs":[],"source":["# group the data by company name and count the number of addresses in the left dataframe\n","left_counts = left_no_duplicates.groupby('name').count()['address']\n","\n","# filter companies with more than 80 addresses in left dataframe\n","left_counts = left_counts[left_counts > 80]\n","\n","# sort the left_counts by the count of addresses in descending order\n","left_counts = left_counts.sort_values(ascending=False)\n","\n","# plot the count of addresses for each company in the left dataframe, sorted by the count of addresses in descending order\n","ax = left_counts.plot(kind='bar', figsize=(10, 5))\n","ax.set_title('Number of addresses for each company in the left dataframe')\n","ax.set_xlabel('Company name')\n","ax.set_ylabel('Count')\n","plt.show()"],"id":"dQtdWDXPymA1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ze38PWlTypCr"},"outputs":[],"source":["# group the data by company name and count the number of addresses in the right dataframe\n","right_counts = right_no_duplicates.groupby('name').count()['address']\n","\n","# print the frequency of the counts of addresses for each company in the right dataframe\n","print(right_counts.value_counts().sort_index(ascending=False))\n","\n","# group the data by company name and count the number of addresses\n","right_counts = right_no_duplicates.groupby('name').count()['address']\n","\n","# filter companies with 3 addresses in right dataframe\n","right_counts = right_counts[right_counts >= 3 ]\n","\n","# plot the count of addresses for each company in the right dataframe\n","ax = right_counts.plot(kind='bar', figsize=(10, 5))\n","ax.set_title('Number of addresses for each company in the right dataframe')\n","ax.set_xlabel('Company name')\n","ax.set_ylabel('Count')\n","plt.show()"],"id":"Ze38PWlTypCr"},{"cell_type":"code","execution_count":null,"metadata":{"id":"faf4cc5d"},"outputs":[],"source":["left_no_duplicates_copy = left_no_duplicates.copy()\n","left_no_duplicates_copy[\"combine\"] = left_no_duplicates_copy[\"name\"] + \" \" + left_no_duplicates_copy[\"address\"]\n","sorted_left = left_no_duplicates_copy.sort_values(by=[\"combine\", \"name\"], ascending=[True, True])\n","sorted_left.head()\n"],"id":"faf4cc5d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"899fb958"},"outputs":[],"source":["right_no_duplicates_copy = right_no_duplicates.copy()\n","right_no_duplicates_copy[\"combine\"] = right_no_duplicates_copy[\"name\"] + \" \" + right_no_duplicates_copy[\"address\"]\n","sorted_right = right_no_duplicates_copy.sort_values(by=\"combine\", ascending=True)\n","sorted_right.head()"],"id":"899fb958"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dee0835"},"outputs":[],"source":["#check on length for matching\n","max_words_left = sorted_left['combine'].str.split().apply(len).max()\n","min_words_left = sorted_left['combine'].str.split().apply(len).min()\n","max_words_right = sorted_right['combine'].str.split().apply(len).max()\n","min_words_right = sorted_right['combine'].str.split().apply(len).min()\n","print(min_words_left, max_words_left, min_words_right, max_words_right)"],"id":"8dee0835"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"b36fa8e3","outputId":"a615042a-cb48-4fe5-ccab-7e53e38e0652"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                    left_combine  left_entity_id  \\\n","0             2 danes 73 white bridge rd ste 109           38004   \n","1      2050s beauty  cosmetic 638 washington ave           63347   \n","2                     2637brew 2637 w girard ave           48782   \n","3            2nd street brew house 1700 s 2nd st           29144   \n","4                  3 dot dash 6203 n florida ave           77266   \n","...                                          ...             ...   \n","2036            zara beauty salon 2206 walnut st           10831   \n","2037                     zfever 4715 n clark ave           36503   \n","2038  zsas gourmet ice cream 6616 germantown ave           43324   \n","2039                 zula  mac 301 lewisburg ave           53221   \n","2040                  zygmunt motors 70 green st           42341   \n","\n","                                   right_combine  right_business_id  \n","0             2 danes 73 white bridge rd ste 109              84508  \n","1      2050s beauty  cosmetic 638 washington ave              77728  \n","2                     2637brew 2637 w girard ave              63296  \n","3            2nd street brew house 1700 s 2nd st              73499  \n","4                  3 dot dash 6203 n florida ave               5412  \n","...                                          ...                ...  \n","2036            zara beauty salon 2206 walnut st              76806  \n","2037                     zfever 4715 n clark ave              25358  \n","2038  zsas gourmet ice cream 6616 germantown ave              72818  \n","2039                 zula  mac 301 lewisburg ave              88017  \n","2040                  zygmunt motors 70 green st              60261  \n","\n","[2041 rows x 4 columns]\n"]}],"source":["#complete matches of combine columns\n","matched_rows = []\n","for index, row in sorted_left.iterrows():\n","    # check if the \"combine\" value is present in the \"combine\" column of the right DataFrame\n","    if row['combine'] in sorted_right['combine'].values:\n","        # if there is a match, find the corresponding row in the right DataFrame and append it to the matched_rows list\n","        right_row = sorted_right[sorted_right['combine'] == row['combine']].iloc[0]\n","        matched_rows.append([row['combine'], row['entity_id'], right_row['combine'], right_row['business_id']])\n","complete_match = pd.DataFrame(matched_rows, columns=['left_combine', 'left_entity_id', 'right_combine', 'right_business_id'])\n","print(complete_match)"],"id":"b36fa8e3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1ca5bdd"},"outputs":[],"source":[" # Define a function to calculate the proportion of matching words between two strings\n"," def calculate_word_match(string1, string2):\n","     # Split each string into words\n","     words1 = set(string1.split())\n","     words2 = set(string2.split())\n","     # Calculate the number of matching words using set intersection\n","     matches = words1 & words2\n","     # Calculate the proportion of matching words\n","     proportion = len(matches) / len(set(words1).union(words2))\n","     return proportion\n","\n"," max_length_diff = 4\n"," matched_rows_dict = {}\n"," matched_rows = []\n","\n"," #iterate through left dataset\n"," for left_index, left_row in sorted_left.iterrows():\n","     left_city, left_state, left_zip, left_combine = left_row['city'], left_row['state'], left_row['postal_code'], left_row['combine']\n","     # filter right dataset by state, city and zip based on current row\n","     right_filtered = sorted_right[(sorted_right['state'] == left_state) & (sorted_right['city'] == left_city) & (sorted_right['zip_code'] == left_zip)]\n","     max_proportion = 0\n","     matched_row = None\n","     #iterate through the rows of the filtered set\n","     for right_index, right_row in right_filtered.iterrows():\n","         right_combine = right_row['combine']\n","         #proceed to calculate proportion if length difference is <= max_length diff \n","         length_diff = abs(len(left_combine) - len(right_combine))\n","         if length_diff <= max_length_diff:\n","             proportion = calculate_word_match(left_combine, right_combine)\n","             #check for highest proportion\n","             if proportion > max_proportion:\n","                 max_proportion = proportion\n","                 matched_row = {'left_entity_id': left_row['entity_id'], 'right_business_id': right_row['business_id'], 'confidence': proportion}\n","             # stop iterating if proportion is 1\n","             elif proportion == 1:\n","                 break\n","     #eliminate duplicate matched rows in the final output.\n","     if matched_row is not None:\n","         key = tuple(matched_row.values())\n","         if key not in matched_rows_dict:\n","             matched_rows_dict[key] = matched_row\n","             matched_rows.append(matched_row)\n","\n"," # Create a new DataFrame from the matched rows list\n"," match = pd.DataFrame(matched_rows)\n","\n"," # Filter rows with confidence greater than 0.8\n"," match = match[match['confidence'] > 0.8] \n"," match.sort_values(by='confidence', ascending=False, inplace=True)\n","\n"," print(match)\n"],"id":"c1ca5bdd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"LXJqieu07UDL"},"outputs":[],"source":["# Define a function to calculate the proportion of matching words between two strings\n","def calculate_word_match(string1, string2):\n","    # Split each string into words\n","    words1 = string1.split()\n","    words2 = string2.split()\n","    len1 = len(words1)\n","    len2 = len(words2)\n","    \n","    # Create a matrix to store the results of subproblems\n","    dp = [[0] * (len2 + 1) for _ in range(len1 + 1)]\n","    \n","    # Fill in the matrix\n","    for i in range(len1):\n","        for j in range(len2):\n","            if words1[i] == words2[j]:\n","                dp[i+1][j+1] = dp[i][j] + 1\n","            else:\n","                dp[i+1][j+1] = max(dp[i+1][j], dp[i][j+1])\n","    \n","    # Calculate the proportion of matching words using the matrix\n","    matches = dp[-1][-1]\n","    proportion = matches / (len1 + len2 - matches)\n","    return proportion\n","\n","max_length_diff = 4\n","matched_rows_dict = {}\n","matched_rows = []\n","\n","#iterate through left dataset\n","for left_index, left_row in sorted_left.iterrows():\n","    left_city, left_state, left_zip, left_combine = left_row['city'], left_row['state'], left_row['postal_code'], left_row['combine']\n","    # filter right dataset by state, city and zip based on current row\n","    right_filtered = sorted_right[(sorted_right['state'] == left_state) & (sorted_right['city'] == left_city) & (sorted_right['zip_code'] == left_zip)]\n","    max_proportion = 0\n","    matched_row = None\n","    #iterate through the rows of the filtered set\n","    for right_index, right_row in right_filtered.iterrows():\n","        right_combine = right_row['combine']\n","        #proceed to calculate proportion if length difference is <= max_length diff \n","        length_diff = abs(len(left_combine) - len(right_combine))\n","        if length_diff <= max_length_diff:\n","            proportion = calculate_word_match(left_combine, right_combine)\n","            #check for highest proportion\n","            if proportion > max_proportion:\n","                max_proportion = proportion\n","                matched_row = {'left_entity_id': left_row['entity_id'], 'right_business_id': right_row['business_id'], 'confidence': proportion}\n","            # stop iterating if proportion is 1\n","            elif proportion == 1:\n","                break\n","    #eliminate duplicate matched rows in the final output.\n","    if matched_row is not None:\n","        key = tuple(matched_row.values())\n","        if key not in matched_rows_dict:\n","            matched_rows_dict[key] = matched_row\n","            matched_rows.append(matched_row)\n","\n","# Create a new DataFrame from the matched rows list\n","match = pd.DataFrame(matched_rows)\n","\n","# Filter rows with confidence greater than 0.8\n","match = match[match['confidence'] > 0.8] \n","match.sort_values(by='confidence', ascending=False, inplace=True)\n","\n","print(match)\n"],"id":"LXJqieu07UDL"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y1jfrNdC9FoF"},"outputs":[],"source":["!pip install fuzzywuzzy"],"id":"Y1jfrNdC9FoF"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8432db20"},"outputs":[],"source":["# Use fuzzy wuzzy to calculate similarity of two strings\n","from fuzzywuzzy import fuzz\n","\n","def calculate_string_similarity(string1, string2):\n","    similarity = fuzz.token_set_ratio(string1, string2) / 100.0\n","    return similarity\n","\n"," max_length_diff = 4\n"," matched_rows_dict = {}\n"," matched_rows = []\n","\n","#iterate through left dataset\n","for left_index, left_row in sorted_left.iterrows():\n","    left_city, left_state, left_zip, left_combine = left_row['city'], left_row['state'], left_row['postal_code'], left_row['combine']\n","    # filter right dataset by state, city and zip based on current row\n","    right_filtered = sorted_right[(sorted_right['state'] == left_state) & (sorted_right['city'] == left_city) & (sorted_right['zip_code'] == left_zip)]\n","    max_similarity = 0\n","    matched_row = None\n","    #iterate through the rows of the filtered set\n","    for right_index, right_row in right_filtered.iterrows():\n","        right_combine = right_row['combine']\n","        #proceed to calculate proportion if length difference is <= max_length diff \n","        length_diff = abs(len(left_combine) - len(right_combine))\n","        if length_diff <= max_length_diff:\n","            similarity = calculate_string_similarity(left_combine, right_combine)\n","            #check for highest proportion\n","            if similarity > max_similarity:\n","                max_similarity = similarity\n","                matched_row = {'left_entity_id': left_row['entity_id'], 'right_business_id': right_row['business_id'], 'confidence': similarity}\n","            # stop iterating if similarity is max\n","            elif similarity == 1:\n","                break\n","    #eliminate duplicate matched rows in the final output.\n","    if matched_row is not None:\n","        key = tuple(matched_row.values())\n","        if key not in matched_rows_dict:\n","            matched_rows_dict[key] = matched_row\n","            matched_rows.append(matched_row)\n","\n","# Create a new DataFrame from the matched rows list\n","match = pd.DataFrame(matched_rows)\n","\n","# Filter rows with confidence greater than 0.8\n","match = match[match['confidence'] > 0.8] \n","match.sort_values(by='confidence', ascending=False, inplace=True)\n","\n","print(match)\n","match.to_csv('match_records.csv', index=False)"],"id":"8432db20"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e63031b9"},"outputs":[],"source":[],"id":"e63031b9"}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":5}